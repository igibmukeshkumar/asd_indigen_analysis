â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                ASD Variant Analysis Pipeline (IndiGen + gnomAD)      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

This repository contains a stepwise bioinformatics pipeline for identifying,
annotating, prioritizing, and statistically evaluating ASD-associated genetic
variants using the IndiGen dataset and global population references from gnomAD.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 1: Variant Identification, Annotation & Prioritization
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
pipeline-step1.sh
â€¢ Preparation of targeted gene BED files
â€¢ Extraction of variants from the IndiGen dataset
â€¢ Variant annotation using standard annotation tools
â€¢ Variant prioritization:
  â€“ Missense variants using REVEL score
  â€“ Loss-of-function variants using LOFTEE
â€¢ ACMGâ€“AMP classification of prioritized variants

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 2: gnomAD Variant Query & File Preparation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
VCF-based (Variant IDâ€“centric):
â€¢ varID_query_gnomAD.sh
â€¢ varID_joint_flatten_gnomad.sh

Gene-based queries:
â€¢ query_gnomAD.sh
â€¢ joint_flatten_gnomad.sh

These scripts query the gnomAD API and generate flattened allele count (AC)
and allele number (AN) tables across global and sub-populations.

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 3: Population-Level Enrichment Analysis
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
maf_fisher_test.R
â€¢ Construction of contingency tables for IndiGen vs. gnomAD populations
â€¢ Fisherâ€™s exact test for variant enrichment analysis
â€¢ Multiple testing correction using Bonferroni adjustment
â€¢ Identification of statistically significant population-specific variants

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 4: Carrier Frequency & Prevalence Estimation
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ Calculation of carrier frequency for ASD-associated variants
â€¢ Estimation of variant prevalence within the IndiGen dataset
â€¢ Gene-level aggregation of variant burden

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
STEP 5: Data Visualization for Research Article
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
data_plot.R
â€¢ Population-wise minor allele frequency (MAF) visualization
â€¢ Integration of statistical significance and ACMG classification
â€¢ Generation of publication-quality figures for the manuscript

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


## ğŸ” **Carrier and Prevalence Rate Estimation**

To analyze genotype data (GT matrix) and compute:

* Per-variant and per-gene raw genotype counts (het/hom)
* Unique per-gene/per-condition/per-MOI statistics
* Carrier and disease prevalence under **autosomal recessive (AR)** and **autosomal dominant (AD)** inheritance models
* Hardy-Weinberg Equilibrium estimates

---

## âš™ï¸ **Step-by-Step Plan**

### âœ… **Assumptions**

1. A **condition** (e.g., WD) may involve multiple variants in one gene.
2. A **condition** (e.g., ASD) may involve multiple **genes**.
3. A **gene** (e.g., *FMR1*) can cause multiple **conditions** â€” **pleiotropy**.

---

### ğŸ§© **Step 1: Script Interface**

Write a shell wrapper: `cr_pr.sh`, which calls a Python script:

```bash
Usage: ./cr_pr.sh -gf <GenotypeFile> -qf <QueryFile> -o <OutputFile>
  -gf, --GTfile       Path to genotype matrix file
  -qf, --Queryfile    Path to query file (variant-gene-moi-condition)
  -o,  --Output       Output file path
  -h,  --help         Display this help message
```

---

### ğŸ“„ **Step 2: Input File Format**

**Genotype File**

```
variant	s1	s2	s3	s4
v1	    0/1	0/0	0/0	0/0
...
```

**Query File**

```
variant	gene	moi	condition
v1	    g1	  AR	  ASD
...
```

---

### ğŸ”¢ **Step 3: Data Integration**

* Match `variant` entries between genotype and query file.
* Add `gene`, `moi`, and `condition` as metadata to each variant row.

---

### ğŸ“Š **Step 4: Genotype Counting**

#### A. **Per Variant (Row-wise)**

* `het_raw_per_variant`: count of `0/1, 1/0, 0|1, 1|0, ./1, 1/.`
* `hom_raw_per_variant`: count of `1/1, 1|1`

#### B. **Per Gene**

* `het_raw_per_gene`: total hets across all variants in the same gene.
* `hom_raw_per_gene`: total homs across all variants in the same gene.

#### C. **Unique Per Gene+MOI**

* `uniq_het_for_moi_per_gene`: 1 count per sample if at least one **het** only.
* `uniq_hom_for_moi_per_gene`: 1 count per sample if at least one **hom**, even if both het & hom.

---

### ğŸ§¬ **Step 5: Disease Model-Based Aggregation**

#### For **AR (Recessive)**

* `uniq_het_for_rec_pcond_CARRIER`: total unique **carrier** samples per condition.
* `uniq_hom_for_rec_pcond_DISEASED`: total unique **disease** samples per condition.

Rules:

* If sample has both het and hom, count it as **hom** only.
* Count only once per sample even if multiple het/hom variants.

#### For **AD (Dominant)**

* `uniq_hethom_for_dom_pcond_DISEASED`: count samples with **any het or hom** in a gene.
* If both are present in a sample â†’ count once as **hom** (dominant disease logic).

---

### ğŸ§® **Step 6: Hardy-Weinberg Equilibrium (HWE) Calculations**

**Given:**

* popsize = number of samples in genotype file

#### For **AR conditions**:

* `NORMAL_AC` = 2 Ã— (popsize âˆ’ carriers âˆ’ diseased)
* `CARRIER_AC` = number of **carriers**
* `DISEASED_AC` = 2 Ã— number of **diseased**

Then:

* **PÂ²\_NORMAL\_REC** = (NORMAL\_AC)Â² / (2 Ã— popsize)Â²
* **2PQ\_CARRIER\_REC** = CARRIER\_AC / popsize
* **QÂ²\_DISEASED\_REC** = (1 - P)Â²

#### For **AD conditions**:

* **PREVALENCE\_DOM** = (uniq\_hethom\_for\_dom\_pcond\_DISEASED) / popsize

---

### ğŸ§¾ **Step 7: Output Format**

All columns summarized for downstream use:

| variant | gene | moi | condition | het\_raw\_per\_variant | hom\_raw\_per\_variant | het\_raw\_per\_gene | hom\_raw\_per\_gene | uniq\_het\_for\_moi\_per\_gene | uniq\_hom\_for\_moi\_per\_gene | uniq\_het\_for\_rec\_pcond\_CARRIER | uniq\_hom\_for\_rec\_pcond\_DISEASED | uniq\_hethom\_for\_dom\_pcond\_DISEASED | 
| ------- | ---- | --- | --------- | ---------------------- | ---------------------- | ------------------- | ------------------- | ------------------------------ | ------------------------------ | ----------------------------------- | ------------------------------------ | --------------------------------------- |
